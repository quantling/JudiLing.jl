var documenterSearchIndex = {"docs":
[{"location":"man/pickle/","page":"Utils","title":"Utils","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/pickle/#Utils","page":"Utils","title":"Utils","text":"","category":"section"},{"location":"man/pickle/","page":"Utils","title":"Utils","text":"  mypickle\n  myunpickle","category":"page"},{"location":"man/pickle/#JudiLing.mypickle","page":"Utils","title":"JudiLing.mypickle","text":"save pickle from python pickle file\n\n\n\n\n\n","category":"function"},{"location":"man/pickle/#JudiLing.myunpickle","page":"Utils","title":"JudiLing.myunpickle","text":"load pickle from python pickle file\n\n\n\n\n\n","category":"function"},{"location":"man/utils/","page":"Utils","title":"Utils","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/utils/#Utils","page":"Utils","title":"Utils","text":"","category":"section"},{"location":"man/utils/","page":"Utils","title":"Utils","text":"  iscorrect\n  display_pred\n  translate\n  translate_path\n  is_truly_sparse\n  isattachable\n  iscomplete\n  isstart\n  isnovel\n  check_used_token\n  cal_max_timestep","category":"page"},{"location":"man/utils/#JudiLing.iscorrect","page":"Utils","title":"JudiLing.iscorrect","text":"Check whether the predictions are correct.\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.display_pred","page":"Utils","title":"JudiLing.display_pred","text":"Display prediction nicely.\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.translate","page":"Utils","title":"JudiLing.translate","text":"Translate indices into words or utterances\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.translate_path","page":"Utils","title":"JudiLing.translate_path","text":"Append indices together to form a path\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.is_truly_sparse","page":"Utils","title":"JudiLing.is_truly_sparse","text":"Check whether a matrix is truly sparse regardless its format, where M is originally a sparse matrix format.\n\n\n\n\n\nCheck whether a matrix is truly sparse regardless its format, where M is originally a dense matrix format.\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.isattachable","page":"Utils","title":"JudiLing.isattachable","text":"Check whether a gram can attach to another gram.\n\n\n\n\n\nCheck whether a gram can attach to another gram.\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.iscomplete","page":"Utils","title":"JudiLing.iscomplete","text":"Check whether a path is complete.\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.isstart","page":"Utils","title":"JudiLing.isstart","text":"Check whether a gram can start a path.\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.isnovel","page":"Utils","title":"JudiLing.isnovel","text":"Check whether a predicted path is in training data.\n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.check_used_token","page":"Utils","title":"JudiLing.check_used_token","text":"Check whether there are tokens already used in dataset as n-gram components. \n\n\n\n\n\n","category":"function"},{"location":"man/utils/#JudiLing.cal_max_timestep","page":"Utils","title":"JudiLing.cal_max_timestep","text":"Calculate the max timestep given training and validation datasets.\n\n\n\n\n\nCalculate the max timestep given training datasets only.\n\n\n\n\n\n","category":"function"},{"location":"man/make_adjacency_matrix/","page":"Make Adjacency Matrix","title":"Make Adjacency Matrix","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/make_adjacency_matrix/#Make-Adjacency-Matrix","page":"Make Adjacency Matrix","title":"Make Adjacency Matrix","text":"","category":"section"},{"location":"man/make_adjacency_matrix/","page":"Make Adjacency Matrix","title":"Make Adjacency Matrix","text":"  make_adjacency_matrix\n  make_adjacency_matrix(::Dict)","category":"page"},{"location":"man/make_adjacency_matrix/#JudiLing.make_adjacency_matrix","page":"Make Adjacency Matrix","title":"JudiLing.make_adjacency_matrix","text":"Make full adjacency matrix.\n\n\n\n\n\n","category":"function"},{"location":"man/make_adjacency_matrix/#JudiLing.make_adjacency_matrix-Tuple{Dict}","page":"Make Adjacency Matrix","title":"JudiLing.make_adjacency_matrix","text":"make_adjacency_matrix(::Dict) -> ::SparseMatrixCSC\n\nMake full adjacency matrix based only on the form of n-grams regardless of whether  they are seen in the training data. This usually takes hours for large datasets,  as all possible combinations are considered.\n\n...\n\nObligatory Arguments\n\ni2f::Dict: the dictionary returning features given indices\n\nOptional Arguments\n\ntokenized::Bool=false:if true, the dataset target is assumed to be tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator token\nverbose::Bool=false: if true, more information will be printed\n\nExamples\n\n# without tokenization\ni2f = Dict([(1, \"#ab\"), (2, \"abc\"), (3, \"bc#\"), (4, \"#bc\"), (5, \"ab#\")])\nJudiLing.make_adjacency_matrix(i2f)\n\n# with tokenization\ni2f = Dict([(1, \"#-a-b\"), (2, \"a-b-c\"), (3, \"b-c-#\"), (4, \"#-b-c\"), (5, \"a-b-#\")])\nJudiLing.make_adjacency_matrix(\n  i2f,\n  tokenized=true,\n  sep_token=\"-\")\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/","page":"Cholesky","title":"Cholesky","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/cholesky/#Cholesky","page":"Cholesky","title":"Cholesky","text":"","category":"section"},{"location":"man/cholesky/","page":"Cholesky","title":"Cholesky","text":"  make_transform_fac\n  make_transform_matrix\n  make_transform_fac(::SparseMatrixCSC)\n  make_transform_fac(::Matrix)\n  make_transform_matrix(::Union{LinearAlgebra.Cholesky, SuiteSparse.CHOLMOD.Factor}, ::Union{SparseMatrixCSC, Matrix}, ::Union{SparseMatrixCSC, Matrix})\n  make_transform_matrix(::SparseMatrixCSC, ::Matrix)\n  make_transform_matrix(::Matrix, ::Union{SparseMatrixCSC, Matrix})\n  make_transform_matrix(::SparseMatrixCSC, ::SparseMatrixCSC)\n  format_matrix(::Union{SparseMatrixCSC, Matrix}, ::Symbol)","category":"page"},{"location":"man/cholesky/#JudiLing.make_transform_fac","page":"Cholesky","title":"JudiLing.make_transform_fac","text":"The first part of make transform matrix, usually used by the learn_paths function to  save time and computing resources.\n\n\n\n\n\n","category":"function"},{"location":"man/cholesky/#JudiLing.make_transform_matrix","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"Using Cholesky decomposition to calculate the transformation matrix from S to C  or from C to S.\n\n\n\n\n\n","category":"function"},{"location":"man/cholesky/#JudiLing.make_transform_fac-Tuple{SparseArrays.SparseMatrixCSC}","page":"Cholesky","title":"JudiLing.make_transform_fac","text":"make_transform_fac(::SparseMatrixCSC) -> ::SuiteSparse.CHOLMOD.Factor\n\nCalculate the first step of Cholesky decomposition for sparse matrices.\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_fac-Tuple{Array{T,2} where T}","page":"Cholesky","title":"JudiLing.make_transform_fac","text":"make_transform_fac(::Matrix) -> ::LinearAlgebra.Cholesky\n\nCalculate the first step of Cholesky decomposition for dense matrices.\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_matrix-Tuple{Union{SuiteSparse.CHOLMOD.Factor, LinearAlgebra.Cholesky},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC}}","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"make_transform_matrix(::Union{LinearAlgebra.Cholesky, SuiteSparse.CHOLMOD.Factor}, ::Union{SparseMatrixCSC, Matrix}, ::Union{SparseMatrixCSC, Matrix}) -> ::Union{Matrix, SparseMatrixCSC}\n\nSecond step in calculating the Cholesky decomposition for the transformation matrix.\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_matrix-Tuple{SparseArrays.SparseMatrixCSC,Array{T,2} where T}","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"make_transform_matrix(::SparseMatrixCSC, ::Matrix) -> ::Union{SparseMatrixCSC, Matrix}\n\nUse Cholesky decomposition to calculate the transformation matrix from X to Y, where X is a sparse matrix and Y is a dense matrix.\n\n...\n\nObligatory Arguments\n\nX::SparseMatrixCSC: the X matrix, where X is a sparse matrix\nY::Matrix: the Y matrix, where Y is a dense matrix\n\nOptional Arguments\n\nmethod::Symbol=:additive: whether :additive or :multiplicative decomposition is required\nshift::Float64=0.02: shift value for :additive decomposition\nmultiplier::Float64=1.01: multiplier value for :multiplicative decomposition\noutput_format::Symbol=:auto: to force output format to dense(:dense) or sparse(:sparse), make it auto(:auto) to determined by the program\nsparse_ratio::Float64=0.2: the ratio to decide whether a matrix is sparse\nverbose::Bool=false: if true, more information will be printed out\n\nExamples\n\n# additive mode\nJudiLing.make_transform_matrix(\n  C,\n  S,\n  method=:additive,\n  shift=0.02,\n  verbose=false)\n\n# multiplicative mode\nJudiLing.make_transform_matrix(\n  C,\n  S,\n  method=:multiplicative,\n  multiplier=1.01,\n  verbose=false)\n\nfurther control of sparsity ratio\n\nJudiLing.maketransformmatrix(   ...   outputformat=:auto,   sparseratio=0.2,   ...) ...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_matrix-Tuple{Array{T,2} where T,Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC}}","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"make_transform_matrix(::Matrix, ::Union{SparseMatrixCSC, Matrix}) -> ::Union{SparseMatrixCSC, Matrix}\n\nUse the Cholesky decomposition to calculate the transformation matrix from X to Y, where X is a dense matrix and Y is either a dense matrix or a sparse matrix.\n\n...\n\nObligatory Arguments\n\nX::Matrix: the X matrix, where X is a dense matrix\nY::Union{SparseMatrixCSC, Matrix}: the Y matrix, where Y is either a sparse or a dense matrix\n\nOptional Arguments\n\nmethod::Symbol=:additive: whether :additive or :multiplicative decomposition is required\nshift::Float64=0.02: shift value for :additive decomposition\nmultiplier::Float64=1.01: multiplier value for :multiplicative decomposition\noutput_format::Symbol=:auto: to force output format to dense(:dense) or sparse(:sparse), make it auto(:auto) to determined by the program\nsparse_ratio::Float64=0.2: the ratio to decide whether a matrix is sparse\nverbose::Bool=false: if true, more information will be printed out\n\nExamples\n\n# additive mode\nJudiLing.make_transform_matrix(\n  C,\n  S,\n  method=:additive,\n  shift=0.02,\n  verbose=false)\n\n# multiplicative mode\nJudiLing.make_transform_matrix(\n  C,\n  S,\n  method=:multiplicative,\n  multiplier=1.01,\n  verbose=false)\n\n# further control of sparsity ratio\nJudiLing.make_transform_matrix(\n  ...\n  output_format=:auto,\n  sparse_ratio=0.2,\n  ...)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.make_transform_matrix-Tuple{SparseArrays.SparseMatrixCSC,SparseArrays.SparseMatrixCSC}","page":"Cholesky","title":"JudiLing.make_transform_matrix","text":"make_transform_matrix(::SparseMatrixCSC, ::SparseMatrixCSC) -> ::Union{SparseMatrixCSC, Matrix}\n\nUse the Cholesky decomposition to calculate the transformation matrix from X to Y, where X is a sparse matrix and Y is a sparse matrix.\n\n...\n\nObligatory Arguments\n\nX::SparseMatrixCSC: the X matrix, where X is a sparse matrix\nY::SparseMatrixCSC: the Y matrix, where Y is a sparse matrix\n\nOptional Arguments\n\nmethod::Symbol=:additive: whether :additive or :multiplicative decomposition is required\nshift::Float64=0.02: shift value for :additive decomposition\nmultiplier::Float64=1.01: multiplier value for :multiplicative decomposition\noutput_format::Symbol=:auto: to force output format to dense(:dense) or sparse(:sparse), make it auto(:auto) to determined by the program\nsparse_ratio::Float64=0.2: the ratio to decide whether a matrix is sparse\nverbose::Bool=false: if true, more information will be printed out\n\nExamples\n\n# additive mode\nJudiLing.make_transform_matrix(\n  C,\n  S,\n  method=:additive,\n  shift=0.02,\n  verbose=false)\n\n# multiplicative mode\nJudiLing.make_transform_matrix(\n  C,\n  S,\n  method=:multiplicative,\n  multiplier=1.01,\n  verbose=false)\n\n# further control of sparsity ratio\nJudiLing.make_transform_matrix(\n  ...\n  output_format=:auto,\n  sparse_ratio=0.2,\n  ...)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/cholesky/#JudiLing.format_matrix-Tuple{Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Symbol}","page":"Cholesky","title":"JudiLing.format_matrix","text":"format_matrix(::Union{SparseMatrixCSC, Matrix}, ::Symbol) -> ::Union{SparseMatrixCSC, Matrix}\n\nConvert output matrix format to either a dense matrix or a sparse matrix.\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/","page":"Make Semantic Matrix","title":"Make Semantic Matrix","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/make_semantic_matrix/#Make-Semantic-Matrix","page":"Make Semantic Matrix","title":"Make Semantic Matrix","text":"","category":"section"},{"location":"man/make_semantic_matrix/","page":"Make Semantic Matrix","title":"Make Semantic Matrix","text":"  PS_Matrix_Struct\n  L_Matrix_Struct\n  make_pS_matrix\n  make_S_matrix\n  make_L_matrix\n  make_pS_matrix(::DataFrame)\n  make_pS_matrix(::DataFrame, ::PS_Matrix_Struct)\n  make_S_matrix(::DataFrame, ::Vector, ::Vector)\n  make_S_matrix(::DataFrame, ::DataFrame, ::Vector, ::Vector)\n  make_S_matrix(::DataFrame, ::Vector)\n  make_S_matrix(::DataFrame, ::DataFrame, ::Vector)\n  make_S_matrix(::DataFrame, ::Vector, ::Vector, ::L_Matrix_Struct)\n  make_S_matrix(::DataFrame, ::DataFrame, ::Vector, ::L_Matrix_Struct)\n  make_S_matrix(::DataFrame, ::DataFrame, ::Vector, ::Vector, ::L_Matrix_Struct)\n  make_S_matrix(::DataFrame, ::Vector, ::L_Matrix_Struct)\n  make_L_matrix(::DataFrame, ::Vector, ::Vector)\n  make_L_matrix(::DataFrame, ::Vector)","category":"page"},{"location":"man/make_semantic_matrix/#JudiLing.PS_Matrix_Struct","page":"Make Semantic Matrix","title":"JudiLing.PS_Matrix_Struct","text":"A structure that stores the discrete semantic vectors: pS is the discrete semantic matrix; f2i is a dictionary returning the indices for features; i2f is a dictionary returning the features for indices.\n\n\n\n\n\n","category":"type"},{"location":"man/make_semantic_matrix/#JudiLing.L_Matrix_Struct","page":"Make Semantic Matrix","title":"JudiLing.L_Matrix_Struct","text":"A structure that stores Lexome semantic vectors: L is Lexome semantic matrix; f2i is a dictionary returning the indices for features; i2f is a dictionary returning the features for indices.\n\n\n\n\n\n","category":"type"},{"location":"man/make_semantic_matrix/#JudiLing.make_pS_matrix","page":"Make Semantic Matrix","title":"JudiLing.make_pS_matrix","text":"Make discrete semantic matrix.\n\n\n\n\n\n","category":"function"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"Make simulated semantic matrix.\n\n\n\n\n\n","category":"function"},{"location":"man/make_semantic_matrix/#JudiLing.make_L_matrix","page":"Make Semantic Matrix","title":"JudiLing.make_L_matrix","text":"Make simulated lexome matrix.\n\n\n\n\n\n","category":"function"},{"location":"man/make_semantic_matrix/#JudiLing.make_pS_matrix-Tuple{DataFrames.DataFrame}","page":"Make Semantic Matrix","title":"JudiLing.make_pS_matrix","text":"make_pS_matrix(::DataFrame) -> ::PS_Matrix_Struct\n\nCreate a discrete semantic matrix given a dataframe.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\n\nOptional Arguments\n\nfeatures_col::Symbol=:CommunicativeIntention: the column name for target\nsep_token::String=\"_\": separator\n\nExamples\n\ns_obj_train = JudiLing.make_pS_matrix(\n  utterance,\n  features_col=:CommunicativeIntention,\n  sep_token=\"_\")\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_pS_matrix-Tuple{DataFrames.DataFrame,JudiLing.PS_Matrix_Struct}","page":"Make Semantic Matrix","title":"JudiLing.make_pS_matrix","text":"make_pS_matrix(::DataFrame, ::PS_Matrix_Struct) -> ::PS_Matrix_Struct\n\nConstruct discrete semantic matrix for the validation datasets given by the  exemplar in the dataframe, and given the S matrix for the training datasets.\n\n...\n\nObligatory Arguments\n\nutterances::DataFrame: the dataset\nutterances_train::PS_Matrix_Struct: training PS object\n\nOptional Arguments\n\nfeatures_col::Symbol=:CommunicativeIntention: the column name for target\nsep_token::String=\"_\": separator\n\nExamples\n\ns_obj_val = JudiLing.make_pS_matrix(\n  utterance_val,\n  s_obj_train,\n  features_col=:CommunicativeIntention,\n  sep_token=\"_\")\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,Array{T,1} where T,Array{T,1} where T}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"make_S_matrix(::DataFrame, ::Vector, ::Vector) -> ::Matrix\n\nCreate simulated semantic matrix for the training datasets, given the input data of a vector specified contex lexemes and a vector specified gramatic  lexemes. The semantic vector of a word form is constructed summing semantic  vectors of content and gramatic lexemes.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\nbase::Vector: context lexemes\ninflections::Vector: grammatic lexemes\n\nOptional Arguments\n\nncol::Int64=200: dimension of semantic vectors, usually the same as that of cue vectors\nsd_base_mean::Int64=1: the sd mean of base features\nsd_inflection_mean::Int64=1: the sd mean of inflectional features\nsd_base::Int64=4: the sd of base features\nsd_inflection::Int64=4: the sd of inflectional features\nseed::Int64=314: the random seed\nisdeep::Bool=true: if true, mean of each feature is also randomized \nadd_noise::Bool=true: if true, add additional Gaussian noise\nsd_noise::Int64=1: the sd of the Gaussian noise\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may slightly exceed between 1 or -1 depending on the sd\n\nExamples\n\n# basic usage\nS_train = JudiLing.make_S_matrix(\n  french,\n  [\"Lexeme\"],\n  [\"Tense\",\"Aspect\",\"Person\",\"Number\",\"Gender\",\"Class\",\"Mood\"],\n  ncol=200)\n\n# deep mode\nS_train = JudiLing.make_S_matrix(\n  ...\n  sd_base_mean=1,\n  sd_inflection_mean=1,\n  isdeep=true,\n  ...)\n\n# non-deep mode\nS_train = JudiLing.make_S_matrix(\n  ...\n  isdeep=false,\n  ...)\n\n# add additional Gaussian noise\nS_train = JudiLing.make_S_matrix(\n  ...\n  add_noise=true,\n  sd_noise=1,\n  ...)\n\n# further control of means and standard deviations\nS_train = JudiLing.make_S_matrix(\n  ...\n  sd_base_mean=1,\n  sd_inflection_mean=1,\n  sd_base=4,\n  sd_inflection=4,\n  sd_noise=1,\n  ...)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,DataFrames.DataFrame,Array{T,1} where T,Array{T,1} where T}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"make_S_matrix(::DataFrame, ::DataFrame, ::Vector, ::Vector) -> ::Tuple{Matrix, Matrix}\n\nCreate simulated semantic matrix for the validation datasets, given the input data of a vector specified contex lexemes and a vector specified gramatic  lexemes. The semantic vector of a word form is constructed summing semantic  vectors of content and gramatic lexemes.\n\n...\n\nObligatory Arguments\n\ndata_train::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\nbase::Vector: context lexemes\ninflections::Vector: grammatic lexemes\n\nOptional Arguments\n\nncol::Int64=200: dimension of semantic vectors, usually the same as that of cue vectors\nsd_base_mean::Int64=1: the sd mean of base features\nsd_inflection_mean::Int64=1: the sd mean of inflectional features\nsd_base::Int64=4: the sd of base features\nsd_inflection::Int64=4: the sd of inflectional features\nseed::Int64=314: the random seed\nisdeep::Bool=true: if true, mean of each feature is also randomized \nadd_noise::Bool=true: if true, add additional Gaussian noise\nsd_noise::Int64=1: the sd of the Gaussian noise\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may slightly exceed between 1 or -1 depending on the sd\n\nExamples\n\n# basic usage\nS_train, S_val = JudiLing.make_S_matrix(\n  french,\n  french_val,\n  [\"Lexeme\"],\n  [\"Tense\",\"Aspect\",\"Person\",\"Number\",\"Gender\",\"Class\",\"Mood\"],\n  ncol=200)\n\n# deep mode\nS_train, S_val = JudiLing.make_S_matrix(\n  ...\n  sd_base_mean=1,\n  sd_inflection_mean=1,\n  isdeep=true,\n  ...)\n\n# non-deep mode\nS_train, S_val = JudiLing.make_S_matrix(\n  ...\n  isdeep=false,\n  ...)\n\n# add additional Gaussian noise\nS_train, S_val = JudiLing.make_S_matrix(\n  ...\n  add_noise=true,\n  sd_noise=1,\n  ...)\n\n# further control of means and standard deviations\nS_train, S_val = JudiLing.make_S_matrix(\n  ...\n  sd_base_mean=1,\n  sd_inflection_mean=1,\n  sd_base=4,\n  sd_inflection=4,\n  sd_noise=1,\n  ...)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,Array{T,1} where T}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"make_S_matrix(::DataFrame, ::Vector) -> ::Matrix\n\nCreate simulated semantic matrix for the training datasets with only base  features, given the input data of a vector specified contex lexemes and a  vector specified gramatic lexemes. The semantic vector of a word form is  constructed summing semantic vectors of content and gramatic lexemes.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\nbase::Vector: context lexemes\n\nOptional Arguments\n\nncol::Int64=200: dimension of semantic vectors, usually the same as that of cue vectors\nsd_base_mean::Int64=1: the sd mean of base features\nsd_base::Int64=4: the sd of base features\nseed::Int64=314: the random seed\nisdeep::Bool=true: if true, mean of each feature is also randomized \nadd_noise::Bool=true: if true, add additional Gaussian noise\nsd_noise::Int64=1: the sd of the Gaussian noise\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may slightly exceed between 1 or -1 depending on the sd\n\nExamples\n\n# basic usage\nS_train = JudiLing.make_S_matrix(\n  french,\n  [\"Lexeme\"],\n  ncol=200)\n\n# deep mode\nS_train = JudiLing.make_S_matrix(\n  ...\n  sd_base_mean=1,\n  sd_inflection_mean=1,\n  isdeep=true,\n  ...)\n\n# non-deep mode\nS_train = JudiLing.make_S_matrix(\n  ...\n  isdeep=false,\n  ...)\n\n# add additional Gaussian noise\nS_train = JudiLing.make_S_matrix(\n  ...\n  add_noise=true,\n  sd_noise=1,\n  ...)\n\n# further control of means and standard deviations\nS_train = JudiLing.make_S_matrix(\n  ...\n  sd_base_mean=1,\n  sd_inflection_mean=1,\n  sd_base=4,\n  sd_inflection=4,\n  sd_noise=1,\n  ...)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,DataFrames.DataFrame,Array{T,1} where T}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"make_S_matrix(::DataFrame, ::DataFrame, ::Vector) -> ::Tuple{Matrix, Matrix}\n\nCreate simulated semantic matrix for the validation datasets with only base  features, given the input data of a vector specified contex lexemes and a  vector specified gramatic lexemes. The semantic vector of a word form is  constructed summing semantic vectors of content and gramatic lexemes.\n\n...\n\nObligatory Arguments\n\ndata_train::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\nbase::Vector: context lexemes\n\nOptional Arguments\n\nncol::Int64=200: dimension of semantic vectors, usually the same as that of cue vectors\nsd_base_mean::Int64=1: the sd mean of base features\nsd_base::Int64=4: the sd of base features\nseed::Int64=314: the random seed\nisdeep::Bool=true: if true, mean of each feature is also randomized \nadd_noise::Bool=true: if true, add additional Gaussian noise\nsd_noise::Int64=1: the sd of the Gaussian noise\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may slightly exceed between 1 or -1 depending on the sd\n\nExamples\n\n# basic usage\nS_train, S_val = JudiLing.make_S_matrix(\n  french,\n  french_val,\n  [\"Lexeme\"],\n  ncol=200)\n\n# deep mode\nS_train, S_val = JudiLing.make_S_matrix(\n  ...\n  sd_base_mean=1,\n  sd_inflection_mean=1,\n  isdeep=true,\n  ...)\n\n# non-deep mode\nS_train, S_val = JudiLing.make_S_matrix(\n  ...\n  isdeep=false,\n  ...)\n\n# add additional Gaussian noise\nS_train, S_val = JudiLing.make_S_matrix(\n  ...\n  add_noise=true,\n  sd_noise=1,\n  ...)\n\n# further control of means and standard deviations\nS_train, S_val = JudiLing.make_S_matrix(\n  ...\n  sd_base_mean=1,\n  sd_inflection_mean=1,\n  sd_base=4,\n  sd_inflection=4,\n  sd_noise=1,\n  ...)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,Array{T,1} where T,Array{T,1} where T,JudiLing.L_Matrix_Struct}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"make_S_matrix(::DataFrame, ::Vector, ::Vector, ::L_Matrix_Struct) -> ::Matrix\n\nCreate simulated semantic matrix where lexome matrix is available.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\nbase::Vector: context lexemes\ninflections::Vector: grammatic lexemes\nL::L_Matrix_Struct: the lexome matrix\n\nOptional Arguments\n\nadd_noise::Bool=true: if true, add additional Gaussian noise\nsd_noise::Int64=1: the sd of the Gaussian noise\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may slightly exceed between 1 or -1 depending on the sd\n\nExamples\n\n# basic usage\nS1 = JudiLing.make_S_matrix(\n  latin,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  L1,\n  add_noise=true,\n  sd_noise=1,\n  normalized=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,DataFrames.DataFrame,Array{T,1} where T,JudiLing.L_Matrix_Struct}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"make_S_matrix(::DataFrame, ::DataFrame, ::Vector, ::L_Matrix_Struct) -> ::Union{Matrix, Tuple{Matrix, Matrix}}\n\nCreate simulated semantic matrix where lexome matrix is available.\n\n...\n\nObligatory Arguments\n\ndata_train::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\nbase::Vector: context lexemes\nL::L_Matrix_Struct: the lexome matrix\n\nOptional Arguments\n\nadd_noise::Bool=true: if true, add additional Gaussian noise\nsd_noise::Int64=1: the sd of the Gaussian noise\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may slightly exceed between 1 or -1 depending on the sd\n\nExamples\n\n# basic usage\nS1, S2 = JudiLing.make_S_matrix(\n  latin,\n  latin_val,\n  [\"Lexeme\"],\n  L1,\n  add_noise=true,\n  sd_noise=1,\n  normalized=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,DataFrames.DataFrame,Array{T,1} where T,Array{T,1} where T,JudiLing.L_Matrix_Struct}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"make_S_matrix(::DataFrame, ::DataFrame, ::Vector, ::Vector, ::L_Matrix_Struct) -> ::Union{Matrix, Tuple{Matrix, Matrix}}\n\nCreate simulated semantic matrix where lexome matrix is available.\n\n...\n\nObligatory Arguments\n\ndata_train::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\nbase::Vector: context lexemes\ninflections::Vector: grammatic lexemes\nL::L_Matrix_Struct: the lexome matrix\n\nOptional Arguments\n\nadd_noise::Bool=true: if true, add additional Gaussian noise\nsd_noise::Int64=1: the sd of the Gaussian noise\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may slightly exceed between 1 or -1 depending on the sd\n\nExamples\n\n# basic usage\nS1, S2 = JudiLing.make_S_matrix(\n  latin,\n  latin_val,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  L1,\n  add_noise=true,\n  sd_noise=1,\n  normalized=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_S_matrix-Tuple{DataFrames.DataFrame,Array{T,1} where T,JudiLing.L_Matrix_Struct}","page":"Make Semantic Matrix","title":"JudiLing.make_S_matrix","text":"make_S_matrix(::DataFrame, ::Vector, ::L_Matrix_Struct) -> ::Matrix\n\nCreate simulated semantic matrix where lexome matrix is available.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\nbase::Vector: context lexemes\nL::L_Matrix_Struct: the lexome matrix\n\nOptional Arguments\n\nadd_noise::Bool=true: if true, add additional Gaussian noise\nsd_noise::Int64=1: the sd of the Gaussian noise\nnormalized::Bool=false: if true, most of the values range between 1 and -1, it may slightly exceed between 1 or -1 depending on the sd\n\nExamples\n\n# basic usage\nS1 = JudiLing.make_S_matrix(\n  latin,\n  [\"Lexeme\"],\n  L1,\n  add_noise=true,\n  sd_noise=1,\n  normalized=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_L_matrix-Tuple{DataFrames.DataFrame,Array{T,1} where T,Array{T,1} where T}","page":"Make Semantic Matrix","title":"JudiLing.make_L_matrix","text":"make_L_matrix(::DataFrame, ::Vector, ::Vector) -> ::L_Matrix_Struct\n\nCreate Lexome Matrix with simulated semantic vectors.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\nbase::Vector: context lexemes\ninflections::Vector: grammatic lexemes\n\nOptional Arguments\n\nncol::Int64=200: dimension of semantic vectors, usually the same as that of cue vectors\nsd_base_mean::Int64=1: the sd mean of base features\nsd_inflection_mean::Int64=1: the sd mean of inflectional features\nsd_base::Int64=4: the sd of base features\nsd_inflection::Int64=4: the sd of inflectional features\nseed::Int64=314: the random seed\nisdeep::Bool=true: if true, mean of each feature is also randomized\n\nExamples\n\n# basic usage\nL = JudiLing.make_L_matrix(\n  latin,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  ncol=200)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_semantic_matrix/#JudiLing.make_L_matrix-Tuple{DataFrames.DataFrame,Array{T,1} where T}","page":"Make Semantic Matrix","title":"JudiLing.make_L_matrix","text":"make_L_matrix(::DataFrame, ::Vector) -> ::L_Matrix_Struct\n\nCreate Lexome Matrix with simulated semantic vectors where there are only base features.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\nbase::Vector: context lexemes\n\nOptional Arguments\n\nncol::Int64=200: dimension of semantic vectors, usually the same as that of cue vectors\nsd_base_mean::Int64=1: the sd mean of base features\nsd_base::Int64=4: the sd of base features\nseed::Int64=314: the random seed\nisdeep::Bool=true: if true, mean of each feature is also randomized\n\nExamples\n\n# basic usage\nL = JudiLing.make_L_matrix(\n  latin,\n  [\"Lexeme\"],\n  ncol=200)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/eval/","page":"Evaluation","title":"Evaluation","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/eval/#Find-Paths","page":"Evaluation","title":"Find Paths","text":"","category":"section"},{"location":"man/eval/","page":"Evaluation","title":"Evaluation","text":"  Comp_Acc_Struct\n  accuracy_comprehension\n  eval_SC\n  eval_acc(::Array, ::Array)\n  eval_acc_loose(::Array, ::Array)\n  extract_gpi\n  eval_manual","category":"page"},{"location":"man/eval/#JudiLing.Comp_Acc_Struct","page":"Evaluation","title":"JudiLing.Comp_Acc_Struct","text":"A structure that stores information about comprehension accuracy.\n\n\n\n\n\n","category":"type"},{"location":"man/eval/#JudiLing.accuracy_comprehension","page":"Evaluation","title":"JudiLing.accuracy_comprehension","text":"accuracy_comprehension(::Matrix, ::Matrix) -> ::Comp_Acc_Struct\n\nEvaluate comprehension accuracy.\n\n...\n\nObligatory Arguments\n\nS::Matrix: the (gold standard) S matrix\nShat::Matrix: the (predicted) Shat matrix\ndata::DataFrame: the dataset\n\nOptional Arguments\n\ntarget_col::Union{String, Symbol}=:Words: the column name for target strings\nbase::Vector=[\"Lexeme\"]: base features (typically a lexeme)\ninflections::Union{Nothing, Vector}=nothing: other features (typically in inflectional features)\n\nExamples\n\naccuracy_comprehension(\n  S_train,\n  Shat_train,\n  latin_val,\n  target_col=:Words,\n  base=[\"Lexeme\"],\n  inflections=[\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"]\n  )\n\naccuracy_comprehension(\n  S_val,\n  Shat_val,\n  latin_train,\n  target_col=:Words,\n  base=[\"Lexeme\"],\n  inflections=[\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"]\n  )\n\n...\n\n\n\n\n\n","category":"function"},{"location":"man/eval/#JudiLing.eval_SC","page":"Evaluation","title":"JudiLing.eval_SC","text":"eval_SC(Union{SparseMatrixCSC, Matrix}, Union{SparseMatrixCSC, Matrix}) -> ::Float64\n\nAssess model accuracy on the basis of the correlations of row vectors of Chat and  C or Shat and S. Ideally the target words have highest correlations on the diagonal  of the pertinent correlation matrices.\n\n...\n\nObligatory Arguments\n\nSChat::Union{SparseMatrixCSC, Matrix}: the Chat or Shat matrix\nSC::Union{SparseMatrixCSC, Matrix}: the C or S matrix\n\neval_SC(cue_obj_train.C, Chat_train)\neval_SC(cue_obj_val.C, Chat_val)\neval_SC(S_train, Shat_train)\neval_SC(S_val, Shat_val)\n\n...\n\n\n\n\n\n","category":"function"},{"location":"man/eval/#JudiLing.eval_acc-Tuple{Array,Array}","page":"Evaluation","title":"JudiLing.eval_acc","text":"eval_acc(::Array, ::Array) -> ::Float64\n\nEvaluate the accuracy of the results from learn_paths or build_paths.\n\n...\n\nObligatory Arguments\n\nres::Array: the results from learn_paths or build_paths\ngold_inds::Array: the gold paths' indices\n\nOptional Arguments\n\nverbose::Bool=false: if true, more information is printed\n\nExamples\n\n# evaluation on training data\nacc_train = JudiLing.eval_acc(\n  res_train,\n  cue_obj_train.gold_ind,\n  verbose=false\n)\n\n# evaluation on validation data\nacc_val = JudiLing.eval_acc(\n  res_val,\n  cue_obj_val.gold_ind,\n  verbose=false\n)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/eval/#JudiLing.eval_acc_loose-Tuple{Array,Array}","page":"Evaluation","title":"JudiLing.eval_acc_loose","text":"eval_acc_loose(::Array, ::Array) -> ::Float64\n\nLenient evaluation of the accuracy of the results from learn_paths or build_paths,  counting a prediction as correct when the correlation of the predicted and gold  standard semantic vectors is among the n top correlations, where n is equal to  max_can in the 'learnpaths' or `buildpaths` function.\n\n...\n\nObligatory Arguments\n\nres::Array: the results from learn_paths or build_paths\ngold_inds::Array: the gold paths' indices\n\nOptional Arguments\n\nverbose::Bool=false: if true, more information is printed\n\nExamples\n\n# evaluation on training data\nacc_train_loose = JudiLing.eval_acc_loose(\n  res_train,\n  cue_obj_train.gold_ind,\n  verbose=false\n)\n\n# evaluation on validation data\nacc_val_loose = JudiLing.eval_acc_loose(\n  res_val,\n  cue_obj_val.gold_ind,\n  verbose=false\n)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/eval/#JudiLing.extract_gpi","page":"Evaluation","title":"JudiLing.extract_gpi","text":"extract_gpi(::Vector{Gold_Path_Info_Struct}, ::Float64, ::Float64) -> ::Array\n\nExtract, using gold paths' information, how many n-grams for a gold  path are below the threshold but above the tolerance.\n\n\n\n\n\n","category":"function"},{"location":"man/eval/#JudiLing.eval_manual","page":"Evaluation","title":"JudiLing.eval_manual","text":"eval_manual(::Array, ::DataFrame, ::Dict) -> ::Nothing\n\nCreate extensive reports for the outputs from build_paths and learn_paths.\n\n\n\n\n\n","category":"function"},{"location":"man/find_path/","page":"Find Paths","title":"Find Paths","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/find_path/#Find-Paths","page":"Find Paths","title":"Find Paths","text":"","category":"section"},{"location":"man/find_path/","page":"Find Paths","title":"Find Paths","text":"  Result_Path_Info_Struct\n  Gold_Path_Info_Struct\n  learn_paths\n  build_paths\n  learn_paths(::DataFrame,::DataFrame,::SparseMatrixCSC,::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Matrix,::SparseMatrixCSC,::Dict)\n  build_paths(::DataFrame,::SparseMatrixCSC,::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Matrix,::SparseMatrixCSC,::Dict,::Array)\n  eval_can(::Vector{Vector{Tuple{Vector{Int64}, Int64}}},::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Dict,::Int64,::Bool)\n  find_top_feature_indices(::Matrix, ::Array)","category":"page"},{"location":"man/find_path/#JudiLing.Result_Path_Info_Struct","page":"Find Paths","title":"JudiLing.Result_Path_Info_Struct","text":"Store paths' information built by learn_paths or build_paths\n\n\n\n\n\n","category":"type"},{"location":"man/find_path/#JudiLing.Gold_Path_Info_Struct","page":"Find Paths","title":"JudiLing.Gold_Path_Info_Struct","text":"Store gold paths' information including indices and indices' support and total  support. It can be used to evaluate how low the threshold needs to be set in  order to find most of the correct paths or if set very low, all of the correct paths.\n\n\n\n\n\n","category":"type"},{"location":"man/find_path/#JudiLing.learn_paths","page":"Find Paths","title":"JudiLing.learn_paths","text":"learn_paths(::DataFrame, ::DataFrame, ::SparseMatrixCSC, ::Union{SparseMatrixCSC, Matrix}, ::Union{SparseMatrixCSC, Matrix}, ::Matrix, ::SparseMatrixCSC, ::Dict) -> ::Union{Tuple{Vector{Vector{Result_Path_Info_Struct}}, Vector{Gold_Path_Info_Struct}}, Vector{Vector{Result_Path_Info_Struct}}}\n\nA sequence finding algorithm using discrimination learning to predict, for a given  word, which n-grams are best supported for a given position in the sequence of n-grams.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\nC_train::SparseMatrixCSC: the C matrix for training dataset\nS_val::Union{SparseMatrixCSC, Matrix}: the S matrix for validation dataset\nF_train::Union{SparseMatrixCSC, Matrix}: the F matrix for training dataset\nChat_val::Matrix: the Chat matrix for validation dataset\nA::SparseMatrixCSC: the adjacency matrix\ni2f::Dict: the dictionary returning features given indices\n\nOptional Arguments\n\ngold_ind::Union{Nothing, Vector}=nothing: gold paths' indices\nShat_val::Union{Nothing, Matrix}=nothing: the Shat matrix for the validation dataset\ncheck_gold_path::Bool=false: if true, return a list of support values for the gold path; this information is returned as second output value\nmax_t::Int64=15: maximum timestep\nmax_can::Int64=10: maximum number of candidates to consider\nthreshold::Float64=0.1:the value set for the support such that if the support of an n-gram is higher than this value, the n-gram will be taking into consideration\nis_tolerant::Bool=false: if true, select a specified number (given by max_tolerance) of n-grams whose supports are below threshold but above a second tolerance threshold to be added to the path\ntolerance::Float64=(-1000.0): the value set for the second threshold (in tolerant mode) such that if the support for an n-gram is in between this value and the threshold and the max_tolerance number has not been reached, then allow this n-gram to be added to the path\nmax_tolerance::Int64=4: maximum number of n-grams allowed in a path\ngrams::Int64=3: the number n of grams that make up an n-gram\ntokenized::Bool=false: if true, the dataset target is tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator token\nkeep_sep::Bool=false:if true, keep separators in cues\ntarget_col::Union{String, :Symbol}=:Words: the column name for target strings\nissparse::Symbol=:auto: control of whether output of Mt matrix is a dense matrix or a sparse matrix\nsparse_ratio::Float64=0.2: the ratio to decide whether a matrix is sparse\nverbose::Bool=false: if true, more information is printed\n\nExamples\n\n# basic usage without tokenization\nres = JudiLing.learn_paths(\n  latin,\n  latin,\n  cue_obj.C,\n  S,\n  F,\n  Chat,\n  A,\n  cue_obj.i2f,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=false,\n  keep_sep=false,\n  target_col=:Word,\n  verbose=true)\n\n# basic usage with tokenization\nres = JudiLing.learn_paths(\n  french,\n  french,\n  cue_obj.C,\n  S,\n  F,\n  Chat,\n  A,\n  cue_obj.i2f,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=true,\n  sep_token=\"-\",\n  keep_sep=true,\n  target_col=:Syllables,\n  verbose=true)\n\n# basic usage for validation data\nres_val = JudiLing.learn_paths(\n  latin_train,\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=false,\n  keep_sep=false,\n  target_col=:Word,\n  verbose=true)\n\n# turn on tolerance mode\nres_val = JudiLing.learn_paths(\n  ...\n  threshold=0.1,\n  is_tolerant=true,\n  tolerance=-0.1,\n  max_tolerance=4,\n  ...)\n\n# turn on check gold paths mode\nres_train, gpi_train = JudiLing.learn_paths(\n  ...\n  gold_ind=cue_obj_train.gold_ind,\n  Shat_val=Shat_train,\n  check_gold_path=true,\n  ...)\n\nres_val, gpi_val = JudiLing.learn_paths(\n  ...\n  gold_ind=cue_obj_val.gold_ind,\n  Shat_val=Shat_val,\n  check_gold_path=true,\n  ...)\n\n# control over sparsity\nres_val = JudiLing.learn_paths(\n  ...\n  issparse=:auto,\n  sparse_ratio=0.2,\n  ...)\n\n\n...\n\n\n\n\n\n","category":"function"},{"location":"man/find_path/#JudiLing.build_paths","page":"Find Paths","title":"JudiLing.build_paths","text":"build_paths(::DataFrame,::SparseMatrixCSC,::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Matrix,::SparseMatrixCSC,::Dict,::Array) -> ::Vector{Vector{Result_Path_Info_Struct}}\n\nthe build_paths function constructs paths by only considering those n-grams that are  close to the target. It first takes the predicted c-hat vector and finds the  closest n neighbors in the C matrix. Then it selects all n-grams of these neighbors,  and constructs all valid paths with those n-grams. The path producing the best  correlation with the target semantic vector (through synthesis by analysis) is selected.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\nC_train::SparseMatrixCSC: the C matrix for the training dataset\nS_val::Union{SparseMatrixCSC, Matrix}: the S matrix for the validation dataset\nF_train::Union{SparseMatrixCSC, Matrix}: the F matrix for the training dataset\nChat_val::Matrix: the Chat matrix for the validation dataset\nA::SparseMatrixCSC: the adjacency matrix\ni2f::Dict: the dictionary returning features given indices\nC_train_ind::Array: the gold paths' indices for the training dataset\n\nOptional Arguments\n\nrC::Union{Nothing, Matrix}=nothing: correlation Matrix of C and Chat, specify to save computing time\nmax_t::Int64=15: maximum number of timesteps\nmax_can::Int64=10: maximum number of candidates to consider\nn_neighbors::Int64=10: the top n form neighbors to be considered\ngrams::Int64=3: the number n of grams that make up n-grams\ntokenized::Bool=false: if true, the dataset target is tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator\ntarget_col::Union{String, :Symbol}=:Words: the column name for target strings\nverbose::Bool=false: if true, more information will be printed\n\nExamples\n\n# training dataset\nJudiLing.build_paths(\n  latin_train,\n  cue_obj_train.C,\n  S_train,\n  F_train,\n  Chat_train,\n  A,\n  cue_obj_train.i2f,\n  cue_obj_train.gold_ind,\n  max_t=max_t,\n  n_neighbors=10,\n  verbose=false\n  )\n\n# validation dataset\nJudiLing.build_paths(\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  cue_obj_train.gold_ind,\n  max_t=max_t,\n  n_neighbors=10,\n  verbose=false\n  )\n\n...\n\n\n\n\n\n","category":"function"},{"location":"man/find_path/#JudiLing.learn_paths-Tuple{DataFrames.DataFrame,DataFrames.DataFrame,SparseArrays.SparseMatrixCSC,Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Array{T,2} where T,SparseArrays.SparseMatrixCSC,Dict}","page":"Find Paths","title":"JudiLing.learn_paths","text":"learn_paths(::DataFrame, ::DataFrame, ::SparseMatrixCSC, ::Union{SparseMatrixCSC, Matrix}, ::Union{SparseMatrixCSC, Matrix}, ::Matrix, ::SparseMatrixCSC, ::Dict) -> ::Union{Tuple{Vector{Vector{Result_Path_Info_Struct}}, Vector{Gold_Path_Info_Struct}}, Vector{Vector{Result_Path_Info_Struct}}}\n\nA sequence finding algorithm using discrimination learning to predict, for a given  word, which n-grams are best supported for a given position in the sequence of n-grams.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\nC_train::SparseMatrixCSC: the C matrix for training dataset\nS_val::Union{SparseMatrixCSC, Matrix}: the S matrix for validation dataset\nF_train::Union{SparseMatrixCSC, Matrix}: the F matrix for training dataset\nChat_val::Matrix: the Chat matrix for validation dataset\nA::SparseMatrixCSC: the adjacency matrix\ni2f::Dict: the dictionary returning features given indices\n\nOptional Arguments\n\ngold_ind::Union{Nothing, Vector}=nothing: gold paths' indices\nShat_val::Union{Nothing, Matrix}=nothing: the Shat matrix for the validation dataset\ncheck_gold_path::Bool=false: if true, return a list of support values for the gold path; this information is returned as second output value\nmax_t::Int64=15: maximum timestep\nmax_can::Int64=10: maximum number of candidates to consider\nthreshold::Float64=0.1:the value set for the support such that if the support of an n-gram is higher than this value, the n-gram will be taking into consideration\nis_tolerant::Bool=false: if true, select a specified number (given by max_tolerance) of n-grams whose supports are below threshold but above a second tolerance threshold to be added to the path\ntolerance::Float64=(-1000.0): the value set for the second threshold (in tolerant mode) such that if the support for an n-gram is in between this value and the threshold and the max_tolerance number has not been reached, then allow this n-gram to be added to the path\nmax_tolerance::Int64=4: maximum number of n-grams allowed in a path\ngrams::Int64=3: the number n of grams that make up an n-gram\ntokenized::Bool=false: if true, the dataset target is tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator token\nkeep_sep::Bool=false:if true, keep separators in cues\ntarget_col::Union{String, :Symbol}=:Words: the column name for target strings\nissparse::Symbol=:auto: control of whether output of Mt matrix is a dense matrix or a sparse matrix\nsparse_ratio::Float64=0.2: the ratio to decide whether a matrix is sparse\nverbose::Bool=false: if true, more information is printed\n\nExamples\n\n# basic usage without tokenization\nres = JudiLing.learn_paths(\n  latin,\n  latin,\n  cue_obj.C,\n  S,\n  F,\n  Chat,\n  A,\n  cue_obj.i2f,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=false,\n  keep_sep=false,\n  target_col=:Word,\n  verbose=true)\n\n# basic usage with tokenization\nres = JudiLing.learn_paths(\n  french,\n  french,\n  cue_obj.C,\n  S,\n  F,\n  Chat,\n  A,\n  cue_obj.i2f,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=true,\n  sep_token=\"-\",\n  keep_sep=true,\n  target_col=:Syllables,\n  verbose=true)\n\n# basic usage for validation data\nres_val = JudiLing.learn_paths(\n  latin_train,\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=false,\n  keep_sep=false,\n  target_col=:Word,\n  verbose=true)\n\n# turn on tolerance mode\nres_val = JudiLing.learn_paths(\n  ...\n  threshold=0.1,\n  is_tolerant=true,\n  tolerance=-0.1,\n  max_tolerance=4,\n  ...)\n\n# turn on check gold paths mode\nres_train, gpi_train = JudiLing.learn_paths(\n  ...\n  gold_ind=cue_obj_train.gold_ind,\n  Shat_val=Shat_train,\n  check_gold_path=true,\n  ...)\n\nres_val, gpi_val = JudiLing.learn_paths(\n  ...\n  gold_ind=cue_obj_val.gold_ind,\n  Shat_val=Shat_val,\n  check_gold_path=true,\n  ...)\n\n# control over sparsity\nres_val = JudiLing.learn_paths(\n  ...\n  issparse=:auto,\n  sparse_ratio=0.2,\n  ...)\n\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/find_path/#JudiLing.build_paths-Tuple{DataFrames.DataFrame,SparseArrays.SparseMatrixCSC,Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Array{T,2} where T,SparseArrays.SparseMatrixCSC,Dict,Array}","page":"Find Paths","title":"JudiLing.build_paths","text":"build_paths(::DataFrame,::SparseMatrixCSC,::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Matrix,::SparseMatrixCSC,::Dict,::Array) -> ::Vector{Vector{Result_Path_Info_Struct}}\n\nthe build_paths function constructs paths by only considering those n-grams that are  close to the target. It first takes the predicted c-hat vector and finds the  closest n neighbors in the C matrix. Then it selects all n-grams of these neighbors,  and constructs all valid paths with those n-grams. The path producing the best  correlation with the target semantic vector (through synthesis by analysis) is selected.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\nC_train::SparseMatrixCSC: the C matrix for the training dataset\nS_val::Union{SparseMatrixCSC, Matrix}: the S matrix for the validation dataset\nF_train::Union{SparseMatrixCSC, Matrix}: the F matrix for the training dataset\nChat_val::Matrix: the Chat matrix for the validation dataset\nA::SparseMatrixCSC: the adjacency matrix\ni2f::Dict: the dictionary returning features given indices\nC_train_ind::Array: the gold paths' indices for the training dataset\n\nOptional Arguments\n\nrC::Union{Nothing, Matrix}=nothing: correlation Matrix of C and Chat, specify to save computing time\nmax_t::Int64=15: maximum number of timesteps\nmax_can::Int64=10: maximum number of candidates to consider\nn_neighbors::Int64=10: the top n form neighbors to be considered\ngrams::Int64=3: the number n of grams that make up n-grams\ntokenized::Bool=false: if true, the dataset target is tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator\ntarget_col::Union{String, :Symbol}=:Words: the column name for target strings\nverbose::Bool=false: if true, more information will be printed\n\nExamples\n\n# training dataset\nJudiLing.build_paths(\n  latin_train,\n  cue_obj_train.C,\n  S_train,\n  F_train,\n  Chat_train,\n  A,\n  cue_obj_train.i2f,\n  cue_obj_train.gold_ind,\n  max_t=max_t,\n  n_neighbors=10,\n  verbose=false\n  )\n\n# validation dataset\nJudiLing.build_paths(\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  cue_obj_train.gold_ind,\n  max_t=max_t,\n  n_neighbors=10,\n  verbose=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/find_path/#JudiLing.eval_can-Tuple{Array{Array{Tuple{Array{Int64,1},Int64},1},1},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Union{Array{T,2} where T, SparseArrays.SparseMatrixCSC},Dict,Int64,Bool}","page":"Find Paths","title":"JudiLing.eval_can","text":"eval_can(::Vector{Vector{Tuple{Vector{Int64}, Int64}}},::Union{SparseMatrixCSC, Matrix},::Union{SparseMatrixCSC, Matrix},::Dict,::Int64,::Bool) -> ::Array{Array{Result_Path_Info_Struct,1},1}\n\nCalculate for each candidate path the correlation between predicted semantic  vector and the gold standard semantic vector, and select as target for production  the path with the highest correlation.\n\n\n\n\n\n","category":"method"},{"location":"man/find_path/#JudiLing.find_top_feature_indices-Tuple{Array{T,2} where T,Array}","page":"Find Paths","title":"JudiLing.find_top_feature_indices","text":"find_top_feature_indices(::Matrix, ::Array) -> ::Vector{Vector{Int64}}\n\nFind all indices for the n-grams of the top n closest neighbors of  a given target.\n\n\n\n\n\n","category":"method"},{"location":"man/all_manual/","page":"All Manual index","title":"All Manual index","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/all_manual/","page":"All Manual index","title":"All Manual index","text":"","category":"page"},{"location":"man/output/","page":"Output","title":"Output","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/output/#Output","page":"Output","title":"Output","text":"","category":"section"},{"location":"man/output/","page":"Output","title":"Output","text":"  write2csv\n  write2df\n  write2csv(::Array{Array{Result_Path_Info_Struct,1},1}, ::DataFrame, ::Cue_Matrix_Struct, ::Cue_Matrix_Struct, ::String)\n  write2csv(::Vector{Gold_Path_Info_Struct}, ::String)\n  write2df(::Array{Array{Result_Path_Info_Struct,1},1}, ::DataFrame, ::Cue_Matrix_Struct, ::Cue_Matrix_Struct)\n  write2df(::gpi::Vector{Gold_Path_Info_Struct})","category":"page"},{"location":"man/output/#JudiLing.write2csv","page":"Output","title":"JudiLing.write2csv","text":"Write results into a csv file. This function takes as input the results from the  learn_paths and build_paths functions, including the information on gold paths  that is optionally returned as second output result.\n\n\n\n\n\n","category":"function"},{"location":"man/output/#JudiLing.write2df","page":"Output","title":"JudiLing.write2df","text":"Reformat results into a dataframe. This function takes as input the results from the  learn_paths and build_paths functions, including the information on gold paths  that is optionally returned as second output result.\n\n\n\n\n\n","category":"function"},{"location":"man/output/#JudiLing.write2csv-Tuple{Array{Array{JudiLing.Result_Path_Info_Struct,1},1},DataFrames.DataFrame,JudiLing.Cue_Matrix_Struct,JudiLing.Cue_Matrix_Struct,String}","page":"Output","title":"JudiLing.write2csv","text":"write2csv(::Array{Array{Result_Path_Info_Struct,1},1}, ::DataFrame, ::Cue_Matrix_Struct, ::Cue_Matrix_Struct, ::String) -> ::Nothing\n\nWrite results into csv file for the results from learn_paths and build_paths.\n\n...\n\nObligatory Arguments\n\nres::Array{Array{Result_Path_Info_Struct,1},1}: the results from learn_paths or build_paths\ndata::DataFrame: the dataset\ncue_obj_train::Cue_Matrix_Struct: the cue object for training dataset\ncue_obj_val::Cue_Matrix_Struct: the cue object for validation dataset\nfilename::String: the filename\n\nOptional Arguments\n\ngrams::Int64=3: the number n in n-gram cues\ntokenized::Bool=false: if true, the dataset target is tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator\nstart_end_token::Union{String, Char}=\"#\": start and end token in boundary cues\noutput_sep_token::Union{String, Char}=\"\": output separator\npath_sep_token::Union{String, Char}=\":\": path separator\ntarget_col::Union{String, Symbol}=:Words: the column name for target strings\nroot_dir::String=\".\": dir path for project root dir\noutput_dir::String=\".\": output dir inside root dir\n\nExamples\n\n# writing results for training data\nJudiLing.write2csv(\n  res_train,\n  latin_train,\n  cue_obj_train,\n  cue_obj_train,\n  \"res_latin_train.csv\",\n  grams=3,\n  tokenized=false,\n  sep_token=nothing,\n  start_end_token=\"#\",\n  output_sep_token=\"\",\n  path_sep_token=\":\",\n  target_col=:Word,\n  root_dir=\".\",\n  output_dir=\"test_out\")\n\n# writing results for validation data\nJudiLing.write2csv(\n  res_val,\n  latin_val,\n  cue_obj_train,\n  cue_obj_val,\n  \"res_latin_val.csv\",\n  grams=3,\n  tokenized=false,\n  sep_token=nothing,\n  start_end_token=\"#\",\n  output_sep_token=\"\",\n  path_sep_token=\":\",\n  target_col=:Word,\n  root_dir=\".\",\n  output_dir=\"test_out\")\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/output/#JudiLing.write2csv-Tuple{Array{JudiLing.Gold_Path_Info_Struct,1},String}","page":"Output","title":"JudiLing.write2csv","text":"write2csv(::Vector{Gold_Path_Info_Struct}, ::String) -> ::Nothing\n\nWrite results into csv file for the gold paths' information optionally returned by  learn_paths and build_paths.\n\n...\n\nObligatory Arguments\n\ngpi::Vector{Gold_Path_Info_Struct}: the gold paths' information\nfilename::String: the filename\n\nOptional Arguments\n\nroot_dir::String=\".\": dir path for project root dir\noutput_dir::String=\".\": output dir inside root dir\n\nExamples\n\n# write gold standard paths to csv for training data\nJudiLing.write2csv(\n  gpi_train,\n  \"gpi_latin_train.csv\",\n  root_dir=\".\",\n  output_dir=\"test_out\"\n  )\n\n# write gold standard paths to csv for validation data\nJudiLing.write2csv(\n  gpi_val,\n  \"gpi_latin_val.csv\",\n  root_dir=\".\",\n  output_dir=\"test_out\"\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/output/#JudiLing.write2df-Tuple{Array{Array{JudiLing.Result_Path_Info_Struct,1},1},DataFrames.DataFrame,JudiLing.Cue_Matrix_Struct,JudiLing.Cue_Matrix_Struct}","page":"Output","title":"JudiLing.write2df","text":"write2df(::Array{Array{Result_Path_Info_Struct,1},1}, ::DataFrame, ::Cue_Matrix_Struct, ::Cue_Matrix_Struct) -> ::DataFrame\n\nReformat results into a dataframe for the results form learn_paths and build_paths functions.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\n\nOptional Arguments\n\ngrams::Int64=3: the number n in n-gram cues\ntokenized::Bool=false: if true, the dataset target is tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator\nstart_end_token::Union{String, Char}=\"#\": start and end token in boundary cues\noutput_sep_token::Union{String, Char}=\"\": output separator\npath_sep_token::Union{String, Char}=\":\": path separator\ntarget_col::Union{String, Symbol}=:Words: the column name for target strings\n\nExamples\n\n# writing results for training data\nJudiLing.write2df(\n  res_train,\n  latin_train,\n  cue_obj_train,\n  cue_obj_train,\n  grams=3,\n  tokenized=false,\n  sep_token=nothing,\n  start_end_token=\"#\",\n  output_sep_token=\"\",\n  path_sep_token=\":\",\n  target_col=:Word)\n\n# writing results for validation data\nJudiLing.write2df(\n  res_val,\n  latin_val,\n  cue_obj_train,\n  cue_obj_val,\n  grams=3,\n  tokenized=false,\n  sep_token=nothing,\n  start_end_token=\"#\",\n  output_sep_token=\"\",\n  path_sep_token=\":\",\n  target_col=:Word)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/output/#JudiLing.write2df-Tuple{Array{JudiLing.Gold_Path_Info_Struct,1}}","page":"Output","title":"JudiLing.write2df","text":"write2df(::gpi::Vector{Gold_Path_Info_Struct}) -> ::DataFrame\n\nWrite results into a dataframe for the gold paths' information optionally returned by  learn_paths and build_paths.\n\n...\n\nObligatory Arguments\n\ngpi::Vector{Gold_Path_Info_Struct}: the gold paths' information\n\nExamples\n\n# write gold standard paths to df for training data\nJudiLing.write2csv(gpi_train)\n\n# write gold standard paths to df for validation data\nJudiLing.write2csv(gpi_val)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_yt_matrix/","page":"Make Yt Matrix","title":"Make Yt Matrix","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/make_yt_matrix/#Make-Yt-Matrix","page":"Make Yt Matrix","title":"Make Yt Matrix","text":"","category":"section"},{"location":"man/make_yt_matrix/","page":"Make Yt Matrix","title":"Make Yt Matrix","text":"  make_Yt_matrix\n  make_Yt_matrix(::Int64, ::DataFrame)","category":"page"},{"location":"man/make_yt_matrix/#JudiLing.make_Yt_matrix","page":"Make Yt Matrix","title":"JudiLing.make_Yt_matrix","text":"Make Yt matrix for timestep t.\n\n\n\n\n\n","category":"function"},{"location":"man/make_yt_matrix/#JudiLing.make_Yt_matrix-Tuple{Int64,DataFrames.DataFrame}","page":"Make Yt Matrix","title":"JudiLing.make_Yt_matrix","text":"make_Yt_matrix(::Int64, ::DataFrame) -> ::SparseMatrixCSC\n\nMake Yt matrix for timestep t. A given column of the Yt matrix specifies the support  for the corresponding n-gram predicted for timestep t for each of the observations (rows of Yt).\n\n...\n\nObligatory Arguments\n\nt::Int64: the timestep t\ndata::DataFrame: the dataset\n\nOptional Arguments\n\ntokenized::Bool=false: if true, the dataset target is assumed to be tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator token\nverbose::Bool=false: if verbose, more information will be printed\n\nExamples\n\nlatin = CSV.DataFrame!(CSV.File(joinpath(\"data\", \"latin_mini.csv\")))\nJudiLing.make_Yt_matrix(2, latin)\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/test_combo/","page":"Test Combo","title":"Test Combo","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/test_combo/#Test-Combo","page":"Test Combo","title":"Test Combo","text":"","category":"section"},{"location":"man/test_combo/","page":"Test Combo","title":"Test Combo","text":"  test_combo","category":"page"},{"location":"man/test_combo/#JudiLing.test_combo","page":"Test Combo","title":"JudiLing.test_combo","text":"A wrapper function for a full model for a specific combination of parameters.\n\n\n\n\n\n","category":"function"},{"location":"#JudiLing","page":"Home","title":"JudiLing","text":"","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JudiLing can be installed using the Julia package manager via GitHub web links. In Julia 1.4 REPL, we can run:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> Pkg.add(PackageSpec(url=\"https://github.com/MegamindHenry/JudiLing.jl.git\"))","category":"page"},{"location":"","page":"Home","title":"Home","text":"and in Julia 1.5 REPL, we can run:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> Pkg.add(url=\"https://github.com/MegamindHenry/JudiLing.jl.git\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Or from the Julia REPL, type ] to enter the Pkg REPL mode and run","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/MegamindHenry/JudiLing.jl.git","category":"page"},{"location":"#Running-Julia-with-multiple-threads","page":"Home","title":"Running Julia with multiple threads","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"JudiLing supports the use of multiple threads. Simply start up Julia in your terminal as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"$ julia -t your_num_of_threads","category":"page"},{"location":"","page":"Home","title":"Home","text":"For detailed information on using Julia with threads, see this link.","category":"page"},{"location":"#Include-packages","page":"Home","title":"Include packages","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Before we start, we first need to include two packages in julia:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using JudiLing # our package\nusing CSV # read csv files into dataframes","category":"page"},{"location":"#Quick-start-example","page":"Home","title":"Quick start example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The Latin dataset latin.csv contains lexemes and inflectional features for 672 inflected Latin verb forms for 8 lexemes from 4 conjugation classes. Word forms are inflected for person, number, tense, voice and mood.","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"\",\"Word\",\"Lexeme\",\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"\n\"1\",\"vocoo\",\"vocare\",\"p1\",\"sg\",\"present\",\"active\",\"ind\"\n\"2\",\"vocaas\",\"vocare\",\"p2\",\"sg\",\"present\",\"active\",\"ind\"\n\"3\",\"vocat\",\"vocare\",\"p3\",\"sg\",\"present\",\"active\",\"ind\"\n\"4\",\"vocaamus\",\"vocare\",\"p1\",\"pl\",\"present\",\"active\",\"ind\"\n\"5\",\"vocaatis\",\"vocare\",\"p2\",\"pl\",\"present\",\"active\",\"ind\"\n\"6\",\"vocant\",\"vocare\",\"p3\",\"pl\",\"present\",\"active\",\"ind\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"We first download and read the csv file into Julia:","category":"page"},{"location":"","page":"Home","title":"Home","text":"download(\"https://osf.io/2ejfu/download\", \"latin.csv\")\n\nlatin = CSV.DataFrame!(CSV.File(joinpath(@__DIR__, \"latin.csv\")));","category":"page"},{"location":"","page":"Home","title":"Home","text":"and we can inspect the latin dataframe:","category":"page"},{"location":"","page":"Home","title":"Home","text":"display(latin)","category":"page"},{"location":"","page":"Home","title":"Home","text":"6728 DataFrame. Omitted printing of 2 columns\n Row  Column1  Word            Lexeme   Person  Number  Tense      \n      Int64    String          String   String  String  String     \n\n 1    1        vocoo           vocare   p1      sg      present    \n 2    2        vocaas          vocare   p2      sg      present    \n 3    3        vocat           vocare   p3      sg      present    \n 4    4        vocaamus        vocare   p1      pl      present    \n 5    5        vocaatis        vocare   p2      pl      present    \n 6    6        vocant          vocare   p3      pl      present    \n 7    7        clamoo          clamare  p1      sg      present    \n 8    8        clamaas         clamare  p2      sg      present    \n\n 664  664      carpsisseemus   carpere  p1      pl      pluperfect \n 665  665      carpsisseetis   carpere  p2      pl      pluperfect \n 666  666      carpsissent     carpere  p3      pl      pluperfect \n 667  667      cuccurissem     currere  p1      sg      pluperfect \n 668  668      cuccurissees    currere  p2      sg      pluperfect \n 669  669      cuccurisset     currere  p3      sg      pluperfect \n 670  670      cuccurisseemus  currere  p1      pl      pluperfect \n 671  671      cuccurisseetis  currere  p2      pl      pluperfect \n 672  672      cuccurissent    currere  p3      pl      pluperfect ","category":"page"},{"location":"","page":"Home","title":"Home","text":"For the production model, we want to predict correct forms given their lexemes and inflectional features. For example, giving the lexeme vocare and its inflectional features p1, sg, present, active and ind, the model should produce the form vocoo. On the other hand, the comprehension model takes forms as input and tries to predict their lexemes and inflectional features.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We use letter trigrams to encode our forms. For word vocoo, for example, we use trigrams #vo, voc, oco, coo and oo#. Here, # is used as start/end token to encode the initial trigram and finial trigram of a word. The row vectors of the C matrix specify for each word which of the trigrams are realized in that word.","category":"page"},{"location":"","page":"Home","title":"Home","text":"To make the C matrix, we use the make_cue_matrix function:","category":"page"},{"location":"","page":"Home","title":"Home","text":"cue_obj = JudiLing.make_cue_matrix(\n  latin,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )","category":"page"},{"location":"","page":"Home","title":"Home","text":"Next, we simulate the semantic matrix S using the make_S_matrix function:","category":"page"},{"location":"","page":"Home","title":"Home","text":"n_features = size(cue_obj.C, 2)\nS = JudiLing.make_S_matrix(\n  latin,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  ncol=n_features)","category":"page"},{"location":"","page":"Home","title":"Home","text":"For this simulation, first random vectors are assigned to every lexeme and inflectional feature, and next the vectors of those features are summed up to obtain the semantic vector of the inflected form. Similar dimensions for C and S work best. Therefore, we retrieve the number of columns from the C matrix and pass it to make_S_Matrix when constructing S.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, the next step is to calculate a mapping from S to C by solving equation C = SG. We use Cholesky decomposition to solve this equation:","category":"page"},{"location":"","page":"Home","title":"Home","text":"G = JudiLing.make_transform_matrix(S, cue_obj.C)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, we can make our predicted C matrix Chat:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Chat = S * G","category":"page"},{"location":"","page":"Home","title":"Home","text":"and evaluate the model's prediction accuracy:","category":"page"},{"location":"","page":"Home","title":"Home","text":"@show JudiLing.eval_SC(cue_obj.C, Chat)","category":"page"},{"location":"","page":"Home","title":"Home","text":"JudiLing.eval_SC(cue_obj.C, Chat) = 1.0","category":"page"},{"location":"","page":"Home","title":"Home","text":"Similar to G and Chat, we can solve S = CF:","category":"page"},{"location":"","page":"Home","title":"Home","text":"F = JudiLing.make_transform_matrix(cue_obj.C, S)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and we then calculate the Shat matrix and evaluate comprehension accuracy:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Shat = cue_obj.C * F\n@show JudiLing.eval_SC(S, Shat)","category":"page"},{"location":"","page":"Home","title":"Home","text":"JudiLing.eval_SC(S, Shat) = 1.0","category":"page"},{"location":"","page":"Home","title":"Home","text":"To model speech production, the proper triphones have to be selected and put into the right order. We have two algorithms that accomplish this. Both algorithms construct paths in a triphone space that start with word-initial triphones and end with word-final triphones.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The first step is to construct an adjacency matrix that specify which triphone can follow each other. In this example, we use the adjacency matrix constructed by make_cue_matrix, but we can also make use of a independently constructed adjacency matrix if required.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A = cue_obj.A","category":"page"},{"location":"","page":"Home","title":"Home","text":"For our sequencing algorithms, we calculate the number of timesteps we need for our algorithms. For the Latin dataset, the max timestep is equal to the length of the longest word. The argument :Word specifies the column in the Latin dataset that lists the words' forms.","category":"page"},{"location":"","page":"Home","title":"Home","text":"max_t = JudiLing.cal_max_timestep(latin, :Word)","category":"page"},{"location":"","page":"Home","title":"Home","text":"One sequence finding algorithm used discrimination learning for the position of triphones. This function returns two lists, one with candidate triphone paths and their positional learning support (res) and one with the semantic supports for the gold paths (gpi).","category":"page"},{"location":"","page":"Home","title":"Home","text":"res, gpi = JudiLing.learn_paths(\n  latin, # training dataset\n  latin, # validation dataset, in this example, it's the same as training dataset\n  cue_obj.C,\n  S,\n  F,\n  Chat,\n  A,\n  cue_obj.i2f,\n  check_gold_path=true,\n  gold_ind=cue_obj.gold_ind,\n  Shat_val=Shat,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=false,\n  keep_sep=false,\n  target_col=:Word,\n  verbose=true)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We evaluate the accuracy on the training data as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"acc = JudiLing.eval_acc(\n  res,\n  cue_obj.gold_ind,\n  verbose=false\n)\n\nprintln(\"Acc for train: $acc\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Acc for train: 1.0","category":"page"},{"location":"","page":"Home","title":"Home","text":"The second sequence finding algorithm is usually faster than the first, but does not provide positional learnability estimates.","category":"page"},{"location":"","page":"Home","title":"Home","text":"res_build = JudiLing.build_paths(\n    latin,\n    cue_obj.C,\n    S,\n    F,\n    Chat,\n    A,\n    cue_obj.i2f,\n    cue_obj.gold_ind,\n    max_t=max_t,\n    n_neighbors=3,\n    verbose=true\n    )\n\nacc_build = JudiLing.eval_acc(\n  res_build,\n  cue_obj.gold_ind,\n  verbose=false\n)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Acc for build: 1.0","category":"page"},{"location":"","page":"Home","title":"Home","text":"After having obtained the results from the sequence functions: learn_paths or build_paths, we can save the results either into a csv or into a dataframe, the dataframe can be loaded into R with the rput command of the RCall package.","category":"page"},{"location":"","page":"Home","title":"Home","text":"JudiLing.write2csv(\n  res_learn,\n  latin,\n  cue_obj,\n  cue_obj,\n  \"latin_learn_res.csv\",\n  grams=3,\n  tokenized=false,\n  sep_token=nothing,\n  start_end_token=\"#\",\n  output_sep_token=\"\",\n  path_sep_token=\":\",\n  target_col=:Word,\n  root_dir=@__DIR__,\n  output_dir=\"latin_out\"\n  )\n\ndf_learn = JudiLing.write2df(\n  res_learn,\n  latin,\n  cue_obj,\n  cue_obj,\n  grams=3,\n  tokenized=false,\n  sep_token=nothing,\n  start_end_token=\"#\",\n  output_sep_token=\"\",\n  path_sep_token=\":\",\n  target_col=:Word\n  )\n\nJudiLing.write2csv(\n  res_build,\n  latin,\n  cue_obj,\n  cue_obj,\n  \"latin_build_res.csv\",\n  grams=3,\n  tokenized=false,\n  sep_token=nothing,\n  start_end_token=\"#\",\n  output_sep_token=\"\",\n  path_sep_token=\":\",\n  target_col=:Word,\n  root_dir=@__DIR__,\n  output_dir=\"latin_out\"\n  )\n\ndf_build = JudiLing.write2df(\n  res_build,\n  latin,\n  cue_obj,\n  cue_obj,\n  grams=3,\n  tokenized=false,\n  sep_token=nothing,\n  start_end_token=\"#\",\n  output_sep_token=\"\",\n  path_sep_token=\":\",\n  target_col=:Word\n  )\n\ndisplay(df_learn)\ndisplay(df_build)","category":"page"},{"location":"","page":"Home","title":"Home","text":"2809 DataFrame. Omitted printing of 7 columns\n Row  utterance  identifier \n      Int64?     String?    \n\n 1    1          vocoo      \n 2    2          vocaas     \n 3    2          vocaas     \n 4    2          vocaas     \n 5    3          vocat      \n 6    4          vocaamus   \n 7    4          vocaamus   \n 8    5          vocaatis   \n\n 272  196        vocaamur   \n 273  197        vocaaminii \n 274  197        vocaaminii \n 275  198        vocantur   \n 276  198        vocantur   \n 277  199        clamor     \n 278  200        clamaaris  \n 279  200        clamaaris  \n 280  200        clamaaris  \n6719 DataFrame. Omitted printing of 7 columns\n Row  utterance  identifier \n      Int64?     String?    \n\n 1    1          vocoo      \n 2    1          vocoo      \n 3    1          vocoo      \n 4    2          vocaas     \n 5    2          vocaas     \n 6    2          vocaas     \n 7    2          vocaas     \n 8    3          vocat      \n\n 663  198        vocantur   \n 664  198        vocantur   \n 665  199        clamor     \n 666  199        clamor     \n 667  199        clamor     \n 668  200        clamaaris  \n 669  200        clamaaris  \n 670  200        clamaaris  \n 671  200        clamaaris  ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The model also provides functionality for cross-validation. Here, you can download our datasets, latin_train.csv and latin_val.csv. Please notice that currently our model only support validation datasets that have all their n-grams present in the training datasets.","category":"page"},{"location":"","page":"Home","title":"Home","text":"download(\"https://osf.io/2ejfu/download\", \"latin_train.csv\")\ndownload(\"https://osf.io/bm7y6/download\", \"latin_val.csv\")\n\nlatin_train = CSV.DataFrame!(CSV.File(joinpath(@__DIR__, \"latin_train.csv\")))\nlatin_val = CSV.DataFrame!(CSV.File(joinpath(@__DIR__, \"latin_val.csv\")))","category":"page"},{"location":"","page":"Home","title":"Home","text":"Then, we make the C and S matrices passing both training and validation datasets to the make_cue_matrix function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"cue_obj_train, cue_obj_val = JudiLing.make_cue_matrix(\n  latin_train,\n  latin_val,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\nn_features = size(cue_obj_train.C, 2)\n\nS_train, S_val = JudiLing.make_S_matrix(\n  latin_train,\n  latin_val,\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  ncol=n_features)","category":"page"},{"location":"","page":"Home","title":"Home","text":"After that, we make the transformation matrices, but this time we only use training dataset. We use these transformation matrices to predict the validation dataset.","category":"page"},{"location":"","page":"Home","title":"Home","text":"G_train = JudiLing.make_transform_matrix(S_train, cue_obj_train.C)\nF_train = JudiLing.make_transform_matrix(cue_obj_train.C, S_train)\n\nChat_train = S_train * G_train\nChat_val = S_val * G_train\nShat_train = cue_obj_train.C * F_train\nShat_val = cue_obj_val.C * F_train\n\n@show JudiLing.eval_SC(Chat_train, cue_obj_train.C)\n@show JudiLing.eval_SC(Chat_val, cue_obj_val.C)\n@show JudiLing.eval_SC(Shat_train, S_train)\n@show JudiLing.eval_SC(Shat_val, S_val)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, we can find possible paths through build_paths or learn_paths. Since validation datasets are harder to predict, we turn on tolerant mode which allow the algorithms to find more paths but at the cost of investing more time.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A = cue_obj_train.A\nmax_t = JudiLing.cal_max_timestep(latin_train, latin_val, :Word)\n\nres_train, gpi_train = JudiLing.learn_paths(\n  latin_train,\n  latin_train,\n  cue_obj_train.C,\n  S_train,\n  F_train,\n  Chat_train,\n  A,\n  cue_obj_train.i2f,\n  gold_ind=cue_obj_train.gold_ind,\n  Shat_val=Shat_train,\n  check_gold_path=true,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  tokenized=false,\n  sep_token=\"_\",\n  keep_sep=false,\n  target_col=:Word,\n  issparse=:dense,\n  verbose=true)\n\nres_val, gpi_val = JudiLing.learn_paths(\n  latin_train,\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  gold_ind=cue_obj_val.gold_ind,\n  Shat_val=Shat_val,\n  check_gold_path=true,\n  max_t=max_t,\n  max_can=10,\n  grams=3,\n  threshold=0.1,\n  is_tolerant=true,\n  tolerance=-0.1,\n  max_tolerance=2,\n  tokenized=false,\n  sep_token=\"-\",\n  keep_sep=false,\n  target_col=:Word,\n  issparse=:dense,\n  verbose=true)\n\nacc_train = JudiLing.eval_acc(\n  res_train,\n  cue_obj_train.gold_ind,\n  verbose=false\n)\nacc_val = JudiLing.eval_acc(\n  res_val,\n  cue_obj_val.gold_ind,\n  verbose=false\n)\n\n@show acc_train\n@show acc_val\n\nres_train = JudiLing.build_paths(\n  latin_train,\n  cue_obj_train.C,\n  S_train,\n  F_train,\n  Chat_train,\n  A,\n  cue_obj_train.i2f,\n  cue_obj_train.gold_ind,\n  max_t=max_t,\n  n_neighbors=3,\n  verbose=true\n  )\n\nres_val = JudiLing.build_paths(\n  latin_val,\n  cue_obj_train.C,\n  S_val,\n  F_train,\n  Chat_val,\n  A,\n  cue_obj_train.i2f,\n  cue_obj_train.gold_ind,\n  max_t=max_t,\n  n_neighbors=20,\n  verbose=true\n  )\n\nacc_train = JudiLing.eval_acc(\n  res_train,\n  cue_obj_train.gold_ind,\n  verbose=false\n)\nacc_val = JudiLing.eval_acc(\n  res_val,\n  cue_obj_val.gold_ind,\n  verbose=false\n)\n\n@show acc_train\n@show acc_val","category":"page"},{"location":"","page":"Home","title":"Home","text":"Alternatively, we  have a wrapper function incorporating all above functionalities. In this example, results are placed in a folder named latin_out.","category":"page"},{"location":"","page":"Home","title":"Home","text":"JudiLing.test_combo(\n  joinpath(\"data\", \"latin.csv\"),\n  joinpath(\"latin_out\"), # this is your output dir\n  [\"Lexeme\",\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  [\"Lexeme\"],\n  [\"Person\",\"Number\",\"Tense\",\"Voice\",\"Mood\"],\n  n_grams_target_col=:Word,\n  grams=3,\n  path_method=:learn_paths,\n  train_threshold=0.1,\n  val_threshold=0.01,\n  csv_dir=\"latin_out\",\n  verbose=true)","category":"page"},{"location":"","page":"Home","title":"Home","text":"With this function, you can quickly explore datasets with different parameter settings.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Once you are done, you may want to clean up your output directory:","category":"page"},{"location":"","page":"Home","title":"Home","text":"path = joinpath(@__DIR__, \"latin_out\")\nrm(path, force=true, recursive=true)","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can download and try out this script here.","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you find this package helpful, please cite this as follow:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Luo, X., Chuang, Y. Y., Baayen, R. H. JudiLing: an implementation in Julia of Linear Discriminative Learning algorithms for language model. Eberhard Karls Universitt Tbingen, Seminar fr Sprachwissenschaft.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The following studies have made use of several algorithms now implemented in JudiLing instead of WpmWithLdl:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Baayen, R. H., Chuang, Y. Y., Shafaei-Bajestan, E., and Blevins, J. P. (2019). The discriminative lexicon: A unified computational model for the lexicon and lexical processing in comprehension and production grounded not in (de)composition but in linear discriminative learning. Complexity, 2019, 1-39.\nBaayen, R. H., Chuang, Y. Y., and Blevins, J. P. (2018). Inflectional morphology with linear mappings. The Mental Lexicon, 13 (2), 232-270.\nChuang, Y.-Y., Lo, K., Blevins, J. P., and Baayen, R. H. (in press). Estonian case inflection made simple. A case study in Word and Paradigm morphology with Linear Discriminative Learning. In Krtvlyessy, L., and tekauer, P. (Eds.) Complex Words: Advances in Morphology, 1-19.\nChuang, Y-Y., Bell, M. J., Banke, I., and Baayen, R. H. (accepted). Bilingual and multilingual mental lexicon: a modeling study with Linear Discriminative Learning. Language Learning, 1-55.","category":"page"},{"location":"man/make_cue_matrix/","page":"Make Cue Matrix","title":"Make Cue Matrix","text":"CurrentModule = JudiLing","category":"page"},{"location":"man/make_cue_matrix/#Make-Cue-Matrix","page":"Make Cue Matrix","title":"Make Cue Matrix","text":"","category":"section"},{"location":"man/make_cue_matrix/","page":"Make Cue Matrix","title":"Make Cue Matrix","text":"  Cue_Matrix_Struct\r\n  make_cue_matrix\r\n  make_ngrams\r\n  make_cue_matrix(::DataFrame)\r\n  make_cue_matrix(::DataFrame,::Cue_Matrix_Struct)\r\n  make_cue_matrix(::DataFrame,::DataFrame)\r\n  make_ngrams(::Array,::Int64,::Bool,::Union{Nothing, String, Char},::Union{String, Char})","category":"page"},{"location":"man/make_cue_matrix/#JudiLing.Cue_Matrix_Struct","page":"Make Cue Matrix","title":"JudiLing.Cue_Matrix_Struct","text":"A structure that stores information created by makecuematrix: C is the cue matrix; f2i is a dictionary returning the indices for features; i2f is a dictionary returning the features for indices; gold_ind is a list of indices of gold paths; A is the adjacency matrix.\n\n\n\n\n\n","category":"type"},{"location":"man/make_cue_matrix/#JudiLing.make_cue_matrix","page":"Make Cue Matrix","title":"JudiLing.make_cue_matrix","text":"Construct cue matrix.\n\n\n\n\n\n","category":"function"},{"location":"man/make_cue_matrix/#JudiLing.make_ngrams","page":"Make Cue Matrix","title":"JudiLing.make_ngrams","text":"Given a list of string tokens, extract their n-grams.\n\n\n\n\n\n","category":"function"},{"location":"man/make_cue_matrix/#JudiLing.make_cue_matrix-Tuple{DataFrames.DataFrame}","page":"Make Cue Matrix","title":"JudiLing.make_cue_matrix","text":"make_cue_matrix(::DataFrame) -> ::Cue_Matrix_Struct\n\nMake the cue matrix for training datasets and corresponding indices as well as the adjacency matrix  and gold paths given a dataset in a form of dataframe.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\n\nOptional Arguments\n\ngrams::Int64=3: the number of grams for cues \ntarget_col::Union{String, Symbol}=:Words: the column name for target strings\ntokenized::Bool=false:if true, the dataset target is assumed to be tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator\nkeep_sep::Bool=false: if true, keep separators in cues\nstart_end_token::Union{String, Char}=\"#\": start and end token in boundary cues\nverbose::Bool=false: if true, more information is printed\n\nExamples\n\n# make cue matrix without tokenization\ncue_obj_train = JudiLing.make_cue_matrix(\n  latin_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  sep_token=\"-\",\n  start_end_token=\"#\",\n  keep_sep=false,\n  verbose=false\n  )\n\n# make cue matrix with tokenization\ncue_obj_train = JudiLing.make_cue_matrix(\n  french_train,\n  grams=3,\n  target_col=:Syllables,\n  tokenized=true,\n  sep_token=\"-\",\n  start_end_token=\"#\",\n  keep_sep=true,\n  verbose=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_cue_matrix/#JudiLing.make_cue_matrix-Tuple{DataFrames.DataFrame,JudiLing.Cue_Matrix_Struct}","page":"Make Cue Matrix","title":"JudiLing.make_cue_matrix","text":"make_cue_matrix(::DataFrame, ::Cue_Matrix_Struct) -> ::Cue_Matrix_Struct\n\nMake the cue matrix for validation datasets and corresponding indices as well as the adjacency matrix  and gold paths given a dataset in a form of dataframe.\n\n...\n\nObligatory Arguments\n\ndata::DataFrame: the dataset\ncue_obj::Cue_Matrix_Struct: training cue object\n\nOptional Arguments\n\ngrams::Int64=3: the number of grams for cues \ntarget_col::Union{String, Symbol}=:Words: the column name for target strings\ntokenized::Bool=false:if true, the dataset target is assumed to be tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator\nkeep_sep::Bool=false: if true, keep separators in cues\nstart_end_token::Union{String, Char}=\"#\": start and end token in boundary cues\nverbose::Bool=false: if true, more information is printed\n\nExamples\n\n# make cue matrix without tokenization\ncue_obj_val = JudiLing.make_cue_matrix(\n  latin_val,\n  cue_obj_train,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  sep_token=\"-\",\n  keep_sep=false,\n  start_end_token=\"#\",\n  verbose=false\n  )\n\n# make cue matrix with tokenization\ncue_obj_val = JudiLing.make_cue_matrix(\n  french_val,\n  cue_obj_train,\n  grams=3,\n  target_col=:Syllables,\n  tokenized=true,\n  sep_token=\"-\",\n  keep_sep=true,\n  start_end_token=\"#\",\n  verbose=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_cue_matrix/#JudiLing.make_cue_matrix-Tuple{DataFrames.DataFrame,DataFrames.DataFrame}","page":"Make Cue Matrix","title":"JudiLing.make_cue_matrix","text":"make_cue_matrix(::DataFrame, ::DataFrame) -> ::Cue_Matrix_Struct, ::Cue_Matrix_Struct\n\nMake the cue matrix for traiing and validation datasets at the same time.\n\n...\n\nObligatory Arguments\n\ndata_train::DataFrame: the training dataset\ndata_val::DataFrame: the validation dataset\n\nOptional Arguments\n\ngrams::Int64=3: the number of grams for cues \ntarget_col::Union{String, Symbol}=:Words: the column name for target strings\ntokenized::Bool=false:if true, the dataset target is assumed to be tokenized\nsep_token::Union{Nothing, String, Char}=nothing: separator\nkeep_sep::Bool=false: if true, keep separators in cues\nstart_end_token::Union{String, Char}=\"#\": start and end token in boundary cues\nverbose::Bool=false: if true, more information is printed\n\nExamples\n\n# make cue matrix without tokenization\ncue_obj_train, cue_obj_val = JudiLing.make_cue_matrix(\n  latin_train,\n  latin_val,\n  grams=3,\n  target_col=:Word,\n  tokenized=false,\n  keep_sep=false\n  )\n\n# make cue matrix with tokenization\ncue_obj_train, cue_obj_val = JudiLing.make_cue_matrix(\n  french_train,\n  french_val,\n  grams=3,\n  target_col=:Syllables,\n  tokenized=true,\n  sep_token=\"-\",\n  keep_sep=true,\n  start_end_token=\"#\",\n  verbose=false\n  )\n\n...\n\n\n\n\n\n","category":"method"},{"location":"man/make_cue_matrix/#JudiLing.make_ngrams-Tuple{Array,Int64,Bool,Union{Nothing, Char, String},Union{Char, String}}","page":"Make Cue Matrix","title":"JudiLing.make_ngrams","text":"make_ngrams(::Array, ::Int64, ::Bool, ::Union{Nothing, String, Char},::Union{String, Char} -> ::Array\n\nGiven a list of string tokens return a list of all n-grams for these tokens.\n\n\n\n\n\n","category":"method"}]
}
